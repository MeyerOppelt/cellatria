#########################################
# General Settings (Required for all)
#########################################

# Specifies which LLM provider to use.
# Supported options: "Azure OpenAI", "OpenAI", "Anthropic", "Google", "Local"
PROVIDER="Azure OpenAI"

#########################################
# Azure OpenAI Configuration
# Required if PROVIDER="Azure OpenAI"
#########################################

# Azure OpenAI API key
AZURE_OPENAI_API_KEY=
# Azure OpenAI endpoint (e.g., https://<resource-name>.openai.azure.com/)
AZURE_OPENAI_ENDPOINT=
# The deployment name of your Azure model (e.g., gpt-4o)
AZURE_OPENAI_DEPLOYMENT_NAME=
# Azure OpenAI API version (e.g., 2024-03-01-preview)
AZURE_OPENAI_API_VERSION=
# sampling / generation parameters ---
AZURE_OPENAI_TEMPERATURE=
AZURE_OPENAI_TOP_P=

#########################################
# OpenAI Configuration
# Required if PROVIDER="OpenAI"
#########################################

# Your OpenAI API key (starts with "sk-...", get from https://platform.openai.com/)
OPENAI_API_KEY=
# The model to use (e.g., gpt-4, gpt-3.5-turbo)
OPENAI_MODEL=

#########################################
# Anthropic Configuration
# Required if PROVIDER="Anthropic"
#########################################

# Your Anthropic API key (starts with "sk-ant-...", get from https://console.anthropic.com/)
ANTHROPIC_API_KEY=

#########################################
# Google Gemini / Vertex AI Configuration
# Required if PROVIDER="Google"
#########################################

# Google Gemini API key (get from Google Cloud Console)
GOOGLE_API_KEY=
# Google Gemini model name (e.g., gemini-pro)
GOOGLE_MODEL=

#########################################
# Local Model Configuration (LMStudio, etc.)
# Required if PROVIDER="Local"
#########################################

# Local OpenAI-compatible endpoint (e.g., http://localhost:1234/v1)
LOCAL_BASE_URL=http://localhost:1234/v1
# API key for local model (optional, defaults to "not-needed" for servers like LMStudio/Ollama)
LOCAL_API_KEY=not-needed
# Model name running in LMStudio (optional, can be any string)
LOCAL_MODEL_NAME=local-model
# Temperature for sampling (0.0 to 1.0, optional)
LOCAL_TEMPERATURE=0.7